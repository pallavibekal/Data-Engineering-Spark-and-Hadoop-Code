{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Intro_to_PySpark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pallavibekal/Data-Engineering-Spark-and-Hadoop-Code/blob/main/Intro_to_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3T1Tj2fhbzw"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8LVD5gchbzw"
      },
      "source": [
        "The dataset chosen for this assignment is [Ecommerce customers](https://www.kaggle.com/srolka/ecommerce-customers). The dataset is made up of 500 records and 8 columns. It has customer information, such as e-mail, address, and their color avatar. Then it also has numerical value columns.\n",
        "\n",
        "* Avg Session Length: Average session of in-store style advice sessions\n",
        "* Time on App: Average time spent on App in minutes\n",
        "* Time on Website: Average time spent on Website in minutes\n",
        "* Length of Membership: How many years the customer has been a member.\n",
        "* Yearly Amount Spent\n",
        "\n",
        "Here, we will be using the first four features to perform linear regression using spark and predict Yearly Amount Spent by each customer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS6X9xQQhbzx"
      },
      "source": [
        "### Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLUYa2jkhbzx"
      },
      "source": [
        "**Why do we need Spark?**\n",
        "\n",
        "Spark is one of the latest technologies being used to quickly and easily handle Big Data. Spark is an open-source distributed computing framework that promises a clean and pleasurable experience similar to that of Pandas, while scaling to large data sets via a distributed architecture under the hood. \n",
        "\n",
        "Apache Spark is a powerful cluster computing engine, therefore it is designed for fast computation of big data. Spark runs on Memory (RAM), and that makes the processing much faster than on Disk. It includes \"MLlib\" library to perform Machine Learning tasks using the Spark framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP0oxBKKhbzx"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-MIetu-hbzy"
      },
      "source": [
        "Apache Spark is known as a fast, easy to use and general engine for big data processing, with built-in modules for streaming, SQL, machine learning and graph processing. It’s well-known for its speed, ease of use, generality and the ability to run virtually everywhere. And even though Spark is one of the most asked tools for data engineers, also data scientists can benefit from Spark when doing exploratory data analysis, feature extraction, supervised learning and model evaluation.\n",
        "\n",
        "Spark is a platform for cluster computing that lets you spread data and computations over clusters with multiple nodes (think of each node as a separate computer). Splitting up your data makes it easier to work with very large datasets because each node only works with a small amount of data.\n",
        "\n",
        "As each node works on its own subset of the total data, it also carries out a part of the total calculations required, so that both data processing and computation are performed in parallel over the nodes in the cluster. It is a fact that parallel computation can make certain types of programming tasks much faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2200092\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjoZJWGErxGf"
      },
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"9686800288\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d91d58a-3832-40bb-e4ad-f20af119695c"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook= \"M5_AST_02_Intro_to_PySpark_A\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/CDS/Datasets/ecommerce_customers_.csv\")  \n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "    \n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://cds.iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "  \n",
        "  \n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "  \n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup() \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2200092&recordId=6033\"></script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxCv5teXYANs"
      },
      "source": [
        "### Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB8vMNkUYANt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dwQCqpwhbzy"
      },
      "source": [
        "### PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYVoE0nThbzz"
      },
      "source": [
        "PySpark is an interface for Apache Spark in Python. It not only allows you to write Spark applications using Python APIs, but also provides the PySpark shell for interactively analyzing your data in a distributed environment. PySpark supports most of Spark’s features such as Spark SQL, DataFrame, Streaming, MLlib (Machine Learning) and Spark Core.\n",
        "\n",
        "<figure>\n",
        "<img src='https://cdn.iisc.talentsprint.com/CDS/Images/pyspark_components.png' width = 700 px/>\n",
        "</figure>\n",
        "\n",
        "**Spark SQL and DataFrame**\n",
        "\n",
        "Spark SQL is a Spark module for structured data processing. It provides a programming abstraction called DataFrame and can also act as distributed SQL query engine.\n",
        "\n",
        "**Streaming**\n",
        "\n",
        "Running on top of Spark, the streaming feature in Apache Spark enables powerful interactive and analytical applications across both streaming and historical data, while inheriting Spark’s ease of use and fault tolerance characteristics.\n",
        "\n",
        "**MLlib**\n",
        "\n",
        "Built on top of Spark, MLlib is a scalable machine learning library that provides a uniform set of high-level APIs that help users create and tune practical machine learning pipelines.\n",
        "\n",
        "**Spark Core**\n",
        "\n",
        "Spark Core is the underlying general execution engine for the Spark platform that all other functionality is built on top of. It provides an RDD (Resilient Distributed Dataset) and in-memory computing capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuVyxDSAhbzz"
      },
      "source": [
        "#### Install PySpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpbyJFSZhbzz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960f369e-fdf6-43cc-dd8a-21fe47f46a90"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 36 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 49.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=fcb26781619f8f878e25601d5eae9588ad4d197f2efd74fe1bf0e61b88e43e38\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-JqQmojhbz0"
      },
      "source": [
        "#### Start a Spark Session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vju8S9ZWhbz0"
      },
      "source": [
        "Spark session is a combined entry point of a Spark application, which came into implementation from Spark 2.0. It provides a way to interact with various spark’s functionality with a lesser number of constructs. Instead of having spark context, hive context, SQL context, now everything is encapsulated in a Spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdlUo9HFhbz0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "888ff9ec-3c0d-4b70-e120-d0aa8ea6959b"
      },
      "source": [
        "# Start spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('LinearRegression').getOrCreate()\n",
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://9dcfbbd91d16:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>LinearRegression</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7efd45900050>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryDcIBTYhbz1"
      },
      "source": [
        "### Data Processing using Pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfm30-_ghbz1"
      },
      "source": [
        "#### Loading data into PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YyXV9pthbz1"
      },
      "source": [
        "To load the dataset we will use the `read.csv` module.  The `inferSchema` parameter provided will enable Spark to automatically determine the data type for each column. Also, `header` and `sep` parameters are given as the dataset contains header, and values are separated using vertical bar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g1oX-k0hbz2"
      },
      "source": [
        "df = spark.read.csv(\"ecommerce_customers_.csv\", sep = \"|\", header=True, inferSchema = True)           # creating spark data frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe2TqI_7hbz3"
      },
      "source": [
        "#### Data exploration with PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MOtesQghbz3"
      },
      "source": [
        "* Display data types of dataframe columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_xCliuMhbz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459b0b81-cd7e-49dd-a8df-76ad82ad5b1d"
      },
      "source": [
        "# Print the data types \n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Email', 'string'),\n",
              " ('Address', 'string'),\n",
              " ('Avatar', 'string'),\n",
              " ('Avg Session Length', 'double'),\n",
              " ('Time on App', 'double'),\n",
              " ('Time on Website', 'double'),\n",
              " ('Length of Membership', 'double'),\n",
              " ('Yearly Amount Spent', 'double')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfpmyItPhbz4"
      },
      "source": [
        "* Display column details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOnGCTXZhbz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6094cee1-e221-420e-de11-0ce04c5b889b"
      },
      "source": [
        "# Print the Schema of the DataFrame\n",
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Email: string (nullable = true)\n",
            " |-- Address: string (nullable = true)\n",
            " |-- Avatar: string (nullable = true)\n",
            " |-- Avg Session Length: double (nullable = true)\n",
            " |-- Time on App: double (nullable = true)\n",
            " |-- Time on Website: double (nullable = true)\n",
            " |-- Length of Membership: double (nullable = true)\n",
            " |-- Yearly Amount Spent: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRI0Hi6phbz5"
      },
      "source": [
        "* Display rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4pNnsfwhbz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed288600-7a60-4824-8026-a81c2acbe635"
      },
      "source": [
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------------+------------------+------------------+------------------+--------------------+-------------------+\n",
            "|               Email|             Address|          Avatar|Avg Session Length|       Time on App|   Time on Website|Length of Membership|Yearly Amount Spent|\n",
            "+--------------------+--------------------+----------------+------------------+------------------+------------------+--------------------+-------------------+\n",
            "|mstephenson@ferna...|835 Frank TunnelW...|          Violet| 34.49726772511229| 12.65565114916675| 39.57766801952616|  4.0826206329529615|  587.9510539684005|\n",
            "|   hduke@hotmail.com|4547 Archer Commo...|       DarkGreen| 31.92627202636016|11.109460728682564|37.268958868297744|    2.66403418213262|  392.2049334443264|\n",
            "|    pallen@yahoo.com|24645 Valerie Uni...|          Bisque|33.000914755642675|11.330278057777512|37.110597442120856|   4.104543202376424| 487.54750486747207|\n",
            "|riverarebecca@gma...|1414 David Throug...|     SaddleBrown| 34.30555662975554|13.717513665142507| 36.72128267790313|   3.120178782748092|  581.8523440352177|\n",
            "|mstephens@davidso...|14023 Rodriguez P...|MediumAquaMarine| 33.33067252364639|12.795188551078114| 37.53665330059473|   4.446308318351434|  599.4060920457634|\n",
            "+--------------------+--------------------+----------------+------------------+------------------+------------------+--------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OicqJUYfhbz5"
      },
      "source": [
        "* Display total number of rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVMYaotJhbz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1235fefc-0544-438d-b941-ecf45ec78cad"
      },
      "source": [
        "df.first()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(Email='mstephenson@fernandez.com', Address='835 Frank TunnelWrightmouth, MI 82180-9605', Avatar='Violet', Avg Session Length=34.49726772511229, Time on App=12.65565114916675, Time on Website=39.57766801952616, Length of Membership=4.0826206329529615, Yearly Amount Spent=587.9510539684005)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJLKs8i3hbz6"
      },
      "source": [
        "* Display column labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CbPm_VUhbz6"
      },
      "source": [
        "# YOUR CODE HERE to display column labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbp-QZ3fhbz6"
      },
      "source": [
        "* Display specific columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uicyXLDAhbz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd5759b-bd78-4bbe-b346-7375e0dc3f8c"
      },
      "source": [
        "columns = [\"Email\",\"Time on App\",\"Time on Website\"]\n",
        "df.select(columns).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+------------------+\n",
            "|               Email|       Time on App|   Time on Website|\n",
            "+--------------------+------------------+------------------+\n",
            "|mstephenson@ferna...| 12.65565114916675| 39.57766801952616|\n",
            "|   hduke@hotmail.com|11.109460728682564|37.268958868297744|\n",
            "|    pallen@yahoo.com|11.330278057777512|37.110597442120856|\n",
            "|riverarebecca@gma...|13.717513665142507| 36.72128267790313|\n",
            "|mstephens@davidso...|12.795188551078114| 37.53665330059473|\n",
            "+--------------------+------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyJyBM-Chbz6"
      },
      "source": [
        "* Display the statistics of dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEcVV2Achbz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0811c198-8e3b-4edb-d5e4-2aa652155896"
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+--------------------+-----------+------------------+------------------+------------------+--------------------+-------------------+\n",
            "|summary|            Email|             Address|     Avatar|Avg Session Length|       Time on App|   Time on Website|Length of Membership|Yearly Amount Spent|\n",
            "+-------+-----------------+--------------------+-----------+------------------+------------------+------------------+--------------------+-------------------+\n",
            "|  count|              500|                 500|        500|               500|               500|               500|                 500|                500|\n",
            "|   mean|             null|                null|       null| 33.05319351819619|12.052487937166134| 37.06044542094859|   3.533461555915055|  499.3140382585909|\n",
            "| stddev|             null|                null|       null|0.9925631110845354|0.9942156084725424|1.0104889067564033|  0.9992775024112585|   79.3147815497068|\n",
            "|    min|aaron04@yahoo.com|0001 Mack MillNor...|  AliceBlue|29.532428967057943| 8.508152176032603| 33.91384724758464|  0.2699010899842742| 256.67058229005585|\n",
            "|    max|zscott@wright.com|Unit 7502 Box 834...|YellowGreen| 36.13966248879052|15.126994288792467|40.005181638101895|   6.922689335035808|  765.5184619388373|\n",
            "+-------+-----------------+--------------------+-----------+------------------+------------------+------------------+--------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7ncz4X2hbz7"
      },
      "source": [
        "* Display total distinct values in *Avatar* column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3IUdO7Ohbz7"
      },
      "source": [
        "# Distinct value count\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDwuxwbfhbz8"
      },
      "source": [
        "* Display count of distinct values in *Avatar* column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up-ef7XNhbz8"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5bUrhKkhbz8"
      },
      "source": [
        "* Plot the count of distinct values in *Avatar* column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY39dnmohbz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78bbe69a-d7b9-4ad4-ff16-2f8352c00e57"
      },
      "source": [
        "DF = df.groupby('Avatar').count().sort(\"count\", ascending= False)\n",
        "DF.show(8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "|      Avatar|count|\n",
            "+------------+-----+\n",
            "|   CadetBlue|    7|\n",
            "|   SlateBlue|    7|\n",
            "| GreenYellow|    7|\n",
            "|        Cyan|    7|\n",
            "|        Teal|    7|\n",
            "|   PeachPuff|    6|\n",
            "|      Purple|    6|\n",
            "|LightSkyBlue|    6|\n",
            "+------------+-----+\n",
            "only showing top 8 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy5htH2Rhbz9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "9bff4b51-925c-44f5-c9a5-d1035046db8f"
      },
      "source": [
        "plt.figure(figsize= (24,4))\n",
        "x = DF.toPandas()['Avatar']\n",
        "# YOUR CODE HERE to create y \n",
        "sns.barplot(x, y)\n",
        "plt.xticks(rotation= 90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f8f06a5591cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Avatar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# YOUR CODE HERE to create y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1728x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwFMYWqKhbz9"
      },
      "source": [
        "* Display average time spent on app by users having different *Avatar*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wi64y0Qhbz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "693ae16b-cfb4-42fa-be1a-2b278deb4962"
      },
      "source": [
        "df.groupby('Avatar').avg().select(['Avatar', 'avg(Time on App)']).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|     Avatar|  avg(Time on App)|\n",
            "+-----------+------------------+\n",
            "|ForestGreen|11.801835104426386|\n",
            "|    DimGray|12.013773141157184|\n",
            "|   SeaGreen|11.352012316138753|\n",
            "|       Aqua|12.207605304482167|\n",
            "|       Teal| 11.77888239909872|\n",
            "+-----------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcCKpLhYhbz-"
      },
      "source": [
        "* Display the records where average time spent on website by user is greater than 37 minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLD3pmpQhbz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20cbf9be-787a-49f5-c8cf-5e482acdb77d"
      },
      "source": [
        "df.filter(df['Time on Website'] > 37).show(5) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------------+------------------+------------------+------------------+--------------------+-------------------+\n",
            "|               Email|             Address|          Avatar|Avg Session Length|       Time on App|   Time on Website|Length of Membership|Yearly Amount Spent|\n",
            "+--------------------+--------------------+----------------+------------------+------------------+------------------+--------------------+-------------------+\n",
            "|mstephenson@ferna...|835 Frank TunnelW...|          Violet| 34.49726772511229| 12.65565114916675| 39.57766801952616|  4.0826206329529615|  587.9510539684005|\n",
            "|   hduke@hotmail.com|4547 Archer Commo...|       DarkGreen| 31.92627202636016|11.109460728682564|37.268958868297744|    2.66403418213262|  392.2049334443264|\n",
            "|    pallen@yahoo.com|24645 Valerie Uni...|          Bisque|33.000914755642675|11.330278057777512|37.110597442120856|   4.104543202376424| 487.54750486747207|\n",
            "|mstephens@davidso...|14023 Rodriguez P...|MediumAquaMarine| 33.33067252364639|12.795188551078114| 37.53665330059473|   4.446308318351434|  599.4060920457634|\n",
            "|  awatkins@yahoo.com|Unit 6538 Box 898...|            Aqua|32.739142938380326| 12.35195897300293| 37.37335885854755|  4.4342734348999375|  549.9041461052942|\n",
            "+--------------------+--------------------+----------------+------------------+------------------+------------------+--------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nB82Y8vhbz-"
      },
      "source": [
        "* Display the minimum Yearly Amount Spent where average time spent on website by user is greater than 39 minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7caT8Lvhbz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b51c64a6-bc02-4c65-98da-baf3575a2473"
      },
      "source": [
        "from pyspark.sql.functions import col, min\n",
        "df.filter(col('Time on Website')>13).agg(count('Yearly Amount Spent')).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------+\n",
            "|min(Yearly Amount Spent)|\n",
            "+------------------------+\n",
            "|      350.05820016384513|\n",
            "+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(col('Time on App')>13).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH7kRyvWMHEF",
        "outputId": "7eb8c210-ab76-4145-9009-7cfd8c615689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(col('Time on App')>13).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPOL6X87Mjdu",
        "outputId": "1f6edad6-54be-4ddc-a7c3-fa8fddb09762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+---------------+------------------+------------------+------------------+--------------------+-------------------+\n",
            "|               Email|             Address|         Avatar|Avg Session Length|       Time on App|   Time on Website|Length of Membership|Yearly Amount Spent|\n",
            "+--------------------+--------------------+---------------+------------------+------------------+------------------+--------------------+-------------------+\n",
            "|riverarebecca@gma...|1414 David Throug...|    SaddleBrown| 34.30555662975554|13.717513665142507| 36.72128267790313|   3.120178782748092|  581.8523440352177|\n",
            "|vchurch@walter-ma...|860 Lee KeyWest D...|         Salmon| 33.98777289568564|13.386235275676436|37.534497341555735|  3.2734335777477144|  570.2004089636196|\n",
            "|andrew06@peterson...|26104 Alexander G...|         Tomato|33.992572774953736|13.338975447662113| 37.22580613162114|   2.482607770510596|  492.6060127179966|\n",
            "|taylormason@gmail...|7773 Powell Sprin...|       DarkBlue|32.387975853153876|13.148725692056516| 36.61995708279922|   2.494543646659249|  470.4527333009554|\n",
            "|alejandro75@hotma...|64475 Andre Club ...|           Cyan|32.187812045932155|  14.7153875441565| 38.24411459434352|   1.516575580831944|  452.3156754800354|\n",
            "|samuel46@love-wes...|544 Alexander Hei...|  LightSeaGreen| 32.61785606282345|13.989592555825254|37.190503800397956|   4.064548550437977|   605.061038804892|\n",
            "|vstafford@hotmail...|PSC 5723, Box 815...|          Olive| 31.53160448257291|13.378562784168984| 38.73400628989712|  2.2451477874052825| 436.51560572936256|\n",
            "|heatherhall@yahoo...|8522 Regina Port ...|MediumSlateBlue| 32.33598963740772|13.007819424388568| 37.85177916943607|  2.9963645262685388| 486.83893476506273|\n",
            "|briancarlson@page...|USCGC GillFPO AA ...|    DarkMagenta|32.175501237949376|13.387492105579696| 35.69417498569782|   4.343062915388998|  588.7126055095755|\n",
            "|joshuaodom@gmail.com|5277 Patel BrookE...|  DarkGoldenRod| 32.72836000313375|  13.1045072428758| 38.87804050675985|  2.8200972339734696| 491.07322367951963|\n",
            "|christopher20@gma...|USNV FullerFPO AE...|           Snow| 32.04448612744043|13.414934735851688| 36.11243501077792|  2.2586863869468434|    448.22982918655|\n",
            "|gonzaleskatie@gma...|70129 Darrell Spr...|       Moccasin| 34.56455770619167|13.146551432907062|37.335445894325716|  3.8768751769237673|  593.9150029682891|\n",
            "| william82@gmail.com|11143 Park Square...|     SandyBrown| 33.25633546983111| 13.85806246213124| 37.78026468722867|       5.97676812602|  725.5848140556806|\n",
            "|gregoryholmes@hot...|2891 Martin Plain...|     DarkSalmon| 32.68822929602445|13.761532847115614|39.252930950406224|   2.995761182613056|  520.8987944502368|\n",
            "|    ryan36@gmail.com|5379 Rhonda Prair...|  DarkTurquoise|32.227299136367215|13.728627177429864| 37.99702800956553|   4.802630630523376|  613.5993233689068|\n",
            "|   katie25@gmail.com|6861 Lopez Fork A...|    SpringGreen| 32.77260992960089|13.276313008175375| 36.60077705432864|   3.462298847460372|  540.2634004105403|\n",
            "|      kyang@diaz.org|223 Love Trail Su...|      OliveDrab|34.374258045247466|15.126994288792467|37.157624094065255|   5.377593583586979|  765.5184619388373|\n",
            "|haydenrebecca@gma...|10022 Wilson Orch...|      MintCream|33.879744967981246|  13.5878060830337| 38.26035344266013|  3.2581128828882795|  578.2416050583772|\n",
            "| ilawson@hotmail.com|19018 Christopher...|  DarkGoldenRod| 33.50136982210362|13.898081993497069|37.058912816506904|   4.130562809236324|  596.4301726172282|\n",
            "|audreyjohnson@ros...|USCGC NicholsonFP...|      SlateGray|33.616018552595435|13.516284296962846| 36.77312349371806|   4.125584363255396|  611.0000251040717|\n",
            "+--------------------+--------------------+---------------+------------------+------------------+------------------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1hUIVRAhbz_"
      },
      "source": [
        "* Display the records where average time spent on app by user is greater than 12 minutes and average time spent on website is smaller than 37 minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ-Hib-Bhbz_"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LORVLYUMhb0A"
      },
      "source": [
        "To know more about other `pyspark.sql.functions` operation click [here](https://spark.apache.org/docs/2.4.0/api/python/pyspark.sql.html#module-pyspark.sql.functions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI55eNtchb0A"
      },
      "source": [
        "### Linear Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SQI5Rq3hb0A"
      },
      "source": [
        "Linear Regression model is one of the oldest and widely used machine learning approach which assumes a relationship between dependent and independent variables. It consists of the best fitting line through the scattered points on the graph and this best fitting line is known as the regression line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij78EczBhb0B"
      },
      "source": [
        "#### Setting Up DataFrame for Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exKHqPx4hb0B"
      },
      "source": [
        "For Spark to accept the data, it needs to be in the form of two columns (\"labels\", \"features\")\n",
        "\n",
        "* Features are data points of all the attributes to be used for prediction\n",
        "* Labels are output for each data point\n",
        "* We will be predicting Label from Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCZCS-R4hb0B"
      },
      "source": [
        "For the linear regression model, we need to import two modules from Pyspark i.e. Vector Assembler and Linear Regression. Vector Assembler is a transformer that assembles all the features into one vector from multiple columns that contain type double.\n",
        "\n",
        "To know more about vector assembler click [here](https://spark.apache.org/docs/2.1.0/ml-features.html#vectorassembler)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gHmgn46hb0C"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S26ufGiZhb0C"
      },
      "source": [
        "assembler = VectorAssembler(\n",
        "                            inputCols= [\"Avg Session Length\", \"Time on App\", \"Time on Website\",'Length of Membership'],\n",
        "                            outputCol= \"features\")       # features is the name of output columns which combines all the columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9umLjr7hb0C"
      },
      "source": [
        "output = assembler.transform(df)            # A new column 'features' will be created along with the existing columns\n",
        "                                            # features column will include all the values combined in one list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOxDfY4uhb0D"
      },
      "source": [
        "# YOUR CODE HERE to display first 10 rows of output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l3IvdYNhb0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf101cc5-aed3-4036-9dfc-50f33aaefb3d"
      },
      "source": [
        "output.select(\"features\").show(10, truncate= False)          # displays only the features column (which includes all other column values in a list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------+\n",
            "|features                                                                    |\n",
            "+----------------------------------------------------------------------------+\n",
            "|[34.49726772511229,12.65565114916675,39.57766801952616,4.0826206329529615]  |\n",
            "|[31.92627202636016,11.109460728682564,37.268958868297744,2.66403418213262]  |\n",
            "|[33.000914755642675,11.330278057777512,37.110597442120856,4.104543202376424]|\n",
            "|[34.30555662975554,13.717513665142507,36.72128267790313,3.120178782748092]  |\n",
            "|[33.33067252364639,12.795188551078114,37.53665330059473,4.446308318351434]  |\n",
            "|[33.871037879341976,12.026925339755056,34.47687762925054,5.493507201364199] |\n",
            "|[32.02159550138701,11.366348309710526,36.68377615286961,4.685017246570912]  |\n",
            "|[32.739142938380326,12.35195897300293,37.37335885854755,4.4342734348999375] |\n",
            "|[33.98777289568564,13.386235275676436,37.534497341555735,3.2734335777477144]|\n",
            "|[31.936548618448917,11.814128294972196,37.14516822352819,3.202806071553459] |\n",
            "+----------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsMl8o7Yhb0E"
      },
      "source": [
        "# Complete dataset is represented in 2 columns\n",
        "final_data = output.select(\"features\",'Yearly Amount Spent') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dyT5lLehb0E"
      },
      "source": [
        "#### Splitting the data into Training and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cznY4s_Ahb0F"
      },
      "source": [
        "# Splitting the data in Train and Test set(70% training data, 30% testing data)\n",
        "train_data,test_data = final_data.randomSplit([0.7,0.3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQzau_Pvhb0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f26ca4-4b44-4e44-e9ff-35db7cde34c4"
      },
      "source": [
        "train_data.describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+\n",
            "|summary|Yearly Amount Spent|\n",
            "+-------+-------------------+\n",
            "|  count|                342|\n",
            "|   mean|  497.6122801333889|\n",
            "| stddev|   80.8860181295649|\n",
            "|    min| 256.67058229005585|\n",
            "|    max|  765.5184619388373|\n",
            "+-------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrdTvsmVhb0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091d3337-b266-4e0c-8952-cbdb325de3dc"
      },
      "source": [
        "test_data.describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+\n",
            "|summary|Yearly Amount Spent|\n",
            "+-------+-------------------+\n",
            "|  count|                158|\n",
            "|   mean| 502.99759065617997|\n",
            "| stddev|   75.9224944308872|\n",
            "|    min| 298.76200786180766|\n",
            "|    max|  712.3963268096637|\n",
            "+-------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW62eB6Hhb0G"
      },
      "source": [
        "#### Create a Linear Regression Model object and fit on train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86V5LekMhb0G"
      },
      "source": [
        "regressor = LinearRegression(featuresCol=\"features\", labelCol=\"Yearly Amount Spent\") \n",
        "\n",
        "# Learn to fit the model from training set\n",
        "model = regressor.fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVH4X80nhb0G"
      },
      "source": [
        "#### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCrfunGbhb0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce513c1d-4c76-48d6-cfd4-76fce1d0c7c9"
      },
      "source": [
        "predict = model.transform(test_data)\n",
        "\n",
        "predict.select(predict.columns[:]).show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+------------------+\n",
            "|            features|Yearly Amount Spent|        prediction|\n",
            "+--------------------+-------------------+------------------+\n",
            "|[30.3931845423455...|  319.9288698031936|332.37224360018877|\n",
            "|[30.5743636841713...| 442.06441375806565| 442.4864443655067|\n",
            "|[30.8364326747734...|  467.5019004269896|472.04850488065904|\n",
            "|[30.8794843441274...|  490.2065999848547|494.32495881985005|\n",
            "|[30.9716756438877...|  494.6386097568927| 488.2139824840033|\n",
            "|[31.0662181616375...| 448.93329320767435| 462.2977093421298|\n",
            "|[31.1239743499119...|  486.9470538397658| 508.6936292770554|\n",
            "|[31.2681042107507...|  423.4705331738239| 427.7546215739317|\n",
            "|[31.2834474760581...|  591.7810894256675| 569.7407845810544|\n",
            "|[31.3091926408918...|  432.7207178399336| 430.2028309861696|\n",
            "+--------------------+-------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHlcdOtThb0G"
      },
      "source": [
        "#### Evaluating Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41ftFH8Ohb0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab9ca01-de30-4b8f-d247-4e0c0ab8af2e"
      },
      "source": [
        "# YOUR CODE HERE to create metrics                            # Using evaluate method we can verify our model's performance\n",
        "\n",
        "metrics = model.evaluate(test_data)                             # Using evaluate method we can verify our model's performance\n",
        "\n",
        "print('Mean absolute error: {}'.format(metrics.meanAbsoluteError))\n",
        "print('Root mean squared error: {}'.format(metrics.rootMeanSquaredError))\n",
        "print('R_squared value: {}'.format(metrics.r2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error: 7.863649967165185\n",
            "Root mean squared error: 10.029022579798484\n",
            "R_squared value: 0.9824396278303007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcCSeWV3hb0H"
      },
      "source": [
        "To know more about other operations in pyspark click [here](https://cdn.iisc.talentsprint.com/CDS/cheatSheet_pyspark.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgSwVENIPcM6"
      },
      "source": [
        "# @title In the above given spark dataframe (df), what is the total number of records where average time spent on app by user is greater than 13 minutes? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"92\" #@param [\"\",\"90\",\"91\", \"92\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good and Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"na\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e95ec2-9325-48a1-a8c5-b094279fdd43"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 6033\n",
            "Date of submission:  09 Jan 2022\n",
            "Time of submission:  15:17:42\n",
            "View your submissions: https://cds.iisc.talentsprint.com/notebook_submissions\n"
          ]
        }
      ]
    }
  ]
}